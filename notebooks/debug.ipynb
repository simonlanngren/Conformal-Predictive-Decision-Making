{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add it to sys.path if not already added\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_11</th>\n",
       "      <th>Feature_12</th>\n",
       "      <th>Feature_13</th>\n",
       "      <th>Feature_14</th>\n",
       "      <th>Feature_15</th>\n",
       "      <th>Feature_16</th>\n",
       "      <th>Feature_17</th>\n",
       "      <th>Feature_18</th>\n",
       "      <th>Feature_19</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>0.612458</td>\n",
       "      <td>0.302890</td>\n",
       "      <td>0.834216</td>\n",
       "      <td>0.047399</td>\n",
       "      <td>0.719804</td>\n",
       "      <td>0.447398</td>\n",
       "      <td>0.818309</td>\n",
       "      <td>0.146069</td>\n",
       "      <td>0.358147</td>\n",
       "      <td>0.302147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539084</td>\n",
       "      <td>0.713662</td>\n",
       "      <td>0.197629</td>\n",
       "      <td>0.913003</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.667840</td>\n",
       "      <td>0.860411</td>\n",
       "      <td>0.181674</td>\n",
       "      <td>0.673010</td>\n",
       "      <td>0.386551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6656</th>\n",
       "      <td>0.385603</td>\n",
       "      <td>0.467925</td>\n",
       "      <td>0.907015</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>0.588953</td>\n",
       "      <td>0.644273</td>\n",
       "      <td>0.957890</td>\n",
       "      <td>0.212147</td>\n",
       "      <td>0.585204</td>\n",
       "      <td>0.414145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603729</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.357479</td>\n",
       "      <td>0.486714</td>\n",
       "      <td>0.591230</td>\n",
       "      <td>0.767188</td>\n",
       "      <td>0.668701</td>\n",
       "      <td>0.477242</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.390648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>0.262848</td>\n",
       "      <td>0.606656</td>\n",
       "      <td>0.283377</td>\n",
       "      <td>0.368345</td>\n",
       "      <td>0.918103</td>\n",
       "      <td>0.772905</td>\n",
       "      <td>0.944256</td>\n",
       "      <td>0.926774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834927</td>\n",
       "      <td>0.422072</td>\n",
       "      <td>0.096396</td>\n",
       "      <td>0.481261</td>\n",
       "      <td>0.323096</td>\n",
       "      <td>0.594844</td>\n",
       "      <td>0.936251</td>\n",
       "      <td>0.442993</td>\n",
       "      <td>0.626257</td>\n",
       "      <td>0.536076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>0.195956</td>\n",
       "      <td>0.451717</td>\n",
       "      <td>0.815696</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.346277</td>\n",
       "      <td>0.709878</td>\n",
       "      <td>0.955563</td>\n",
       "      <td>0.135598</td>\n",
       "      <td>0.276597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149316</td>\n",
       "      <td>0.705412</td>\n",
       "      <td>0.797920</td>\n",
       "      <td>0.207436</td>\n",
       "      <td>0.092131</td>\n",
       "      <td>0.423298</td>\n",
       "      <td>0.413823</td>\n",
       "      <td>0.757582</td>\n",
       "      <td>0.139775</td>\n",
       "      <td>0.183488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.180620</td>\n",
       "      <td>0.439045</td>\n",
       "      <td>0.959909</td>\n",
       "      <td>0.322201</td>\n",
       "      <td>0.667473</td>\n",
       "      <td>0.161324</td>\n",
       "      <td>0.580603</td>\n",
       "      <td>0.355139</td>\n",
       "      <td>0.582542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507440</td>\n",
       "      <td>0.476220</td>\n",
       "      <td>0.624558</td>\n",
       "      <td>0.400699</td>\n",
       "      <td>0.703134</td>\n",
       "      <td>0.464292</td>\n",
       "      <td>0.313551</td>\n",
       "      <td>0.110504</td>\n",
       "      <td>0.620457</td>\n",
       "      <td>0.379691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9114</th>\n",
       "      <td>0.408296</td>\n",
       "      <td>0.599392</td>\n",
       "      <td>0.460550</td>\n",
       "      <td>0.328080</td>\n",
       "      <td>0.424042</td>\n",
       "      <td>0.190567</td>\n",
       "      <td>0.314823</td>\n",
       "      <td>0.250036</td>\n",
       "      <td>0.157833</td>\n",
       "      <td>0.470020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669130</td>\n",
       "      <td>0.718851</td>\n",
       "      <td>0.850168</td>\n",
       "      <td>0.136981</td>\n",
       "      <td>0.563640</td>\n",
       "      <td>0.060359</td>\n",
       "      <td>0.391233</td>\n",
       "      <td>0.803318</td>\n",
       "      <td>0.353629</td>\n",
       "      <td>0.412264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556</th>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.655778</td>\n",
       "      <td>0.294223</td>\n",
       "      <td>0.730329</td>\n",
       "      <td>0.794835</td>\n",
       "      <td>0.848344</td>\n",
       "      <td>0.660445</td>\n",
       "      <td>0.097684</td>\n",
       "      <td>0.161359</td>\n",
       "      <td>0.047669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631116</td>\n",
       "      <td>0.764412</td>\n",
       "      <td>0.483582</td>\n",
       "      <td>0.709741</td>\n",
       "      <td>0.672877</td>\n",
       "      <td>0.672708</td>\n",
       "      <td>0.443215</td>\n",
       "      <td>0.131985</td>\n",
       "      <td>0.542839</td>\n",
       "      <td>0.758849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.162311</td>\n",
       "      <td>0.848049</td>\n",
       "      <td>0.124047</td>\n",
       "      <td>0.895527</td>\n",
       "      <td>0.075379</td>\n",
       "      <td>0.854465</td>\n",
       "      <td>0.842951</td>\n",
       "      <td>0.392911</td>\n",
       "      <td>0.266711</td>\n",
       "      <td>0.724984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583445</td>\n",
       "      <td>0.319262</td>\n",
       "      <td>0.206723</td>\n",
       "      <td>0.878003</td>\n",
       "      <td>0.256498</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.587830</td>\n",
       "      <td>0.654521</td>\n",
       "      <td>0.561543</td>\n",
       "      <td>0.554402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>0.516380</td>\n",
       "      <td>0.102074</td>\n",
       "      <td>0.900357</td>\n",
       "      <td>0.725434</td>\n",
       "      <td>0.920071</td>\n",
       "      <td>0.741332</td>\n",
       "      <td>0.269592</td>\n",
       "      <td>0.352505</td>\n",
       "      <td>0.866938</td>\n",
       "      <td>0.102360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155143</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.014080</td>\n",
       "      <td>0.471061</td>\n",
       "      <td>0.782682</td>\n",
       "      <td>0.742665</td>\n",
       "      <td>0.615563</td>\n",
       "      <td>0.353709</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.561791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.670014</td>\n",
       "      <td>0.531847</td>\n",
       "      <td>0.737040</td>\n",
       "      <td>0.114596</td>\n",
       "      <td>0.614844</td>\n",
       "      <td>0.311088</td>\n",
       "      <td>0.909235</td>\n",
       "      <td>0.993776</td>\n",
       "      <td>0.961644</td>\n",
       "      <td>0.236309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795558</td>\n",
       "      <td>0.343304</td>\n",
       "      <td>0.156595</td>\n",
       "      <td>0.625195</td>\n",
       "      <td>0.212004</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.875683</td>\n",
       "      <td>0.577293</td>\n",
       "      <td>0.412293</td>\n",
       "      <td>0.477985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "2436   0.612458   0.302890   0.834216   0.047399   0.719804   0.447398   \n",
       "6656   0.385603   0.467925   0.907015   0.039836   0.588953   0.644273   \n",
       "6474   0.319149   0.809400   0.262848   0.606656   0.283377   0.368345   \n",
       "7529   0.195956   0.451717   0.815696   0.112894   0.054561   0.346277   \n",
       "6601   0.039168   0.180620   0.439045   0.959909   0.322201   0.667473   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9114   0.408296   0.599392   0.460550   0.328080   0.424042   0.190567   \n",
       "8556   0.643564   0.655778   0.294223   0.730329   0.794835   0.848344   \n",
       "315    0.162311   0.848049   0.124047   0.895527   0.075379   0.854465   \n",
       "3701   0.516380   0.102074   0.900357   0.725434   0.920071   0.741332   \n",
       "9      0.670014   0.531847   0.737040   0.114596   0.614844   0.311088   \n",
       "\n",
       "      Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_11  Feature_12  \\\n",
       "2436   0.818309   0.146069   0.358147   0.302147  ...    0.539084    0.713662   \n",
       "6656   0.957890   0.212147   0.585204   0.414145  ...    0.603729    0.780275   \n",
       "6474   0.918103   0.772905   0.944256   0.926774  ...    0.834927    0.422072   \n",
       "7529   0.709878   0.955563   0.135598   0.276597  ...    0.149316    0.705412   \n",
       "6601   0.161324   0.580603   0.355139   0.582542  ...    0.507440    0.476220   \n",
       "...         ...        ...        ...        ...  ...         ...         ...   \n",
       "9114   0.314823   0.250036   0.157833   0.470020  ...    0.669130    0.718851   \n",
       "8556   0.660445   0.097684   0.161359   0.047669  ...    0.631116    0.764412   \n",
       "315    0.842951   0.392911   0.266711   0.724984  ...    0.583445    0.319262   \n",
       "3701   0.269592   0.352505   0.866938   0.102360  ...    0.155143    0.003022   \n",
       "9      0.909235   0.993776   0.961644   0.236309  ...    0.795558    0.343304   \n",
       "\n",
       "      Feature_13  Feature_14  Feature_15  Feature_16  Feature_17  Feature_18  \\\n",
       "2436    0.197629    0.913003    0.001117    0.667840    0.860411    0.181674   \n",
       "6656    0.357479    0.486714    0.591230    0.767188    0.668701    0.477242   \n",
       "6474    0.096396    0.481261    0.323096    0.594844    0.936251    0.442993   \n",
       "7529    0.797920    0.207436    0.092131    0.423298    0.413823    0.757582   \n",
       "6601    0.624558    0.400699    0.703134    0.464292    0.313551    0.110504   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "9114    0.850168    0.136981    0.563640    0.060359    0.391233    0.803318   \n",
       "8556    0.483582    0.709741    0.672877    0.672708    0.443215    0.131985   \n",
       "315     0.206723    0.878003    0.256498    0.185100    0.587830    0.654521   \n",
       "3701    0.014080    0.471061    0.782682    0.742665    0.615563    0.353709   \n",
       "9       0.156595    0.625195    0.212004    0.542169    0.875683    0.577293   \n",
       "\n",
       "      Feature_19    Target  \n",
       "2436    0.673010  0.386551  \n",
       "6656    0.001459  0.390648  \n",
       "6474    0.626257  0.536076  \n",
       "7529    0.139775  0.183488  \n",
       "6601    0.620457  0.379691  \n",
       "...          ...       ...  \n",
       "9114    0.353629  0.412264  \n",
       "8556    0.542839  0.758849  \n",
       "315     0.561543  0.554402  \n",
       "3701    0.923567  0.561791  \n",
       "9       0.412293  0.477985  \n",
       "\n",
       "[1000 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.functions.data_generation import DataGeneration\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = DataGeneration.generate_data(\n",
    "    n_samples=10000,\n",
    "    n_features=20,\n",
    "    n_informative=4,\n",
    "    relationship='friedman1',\n",
    "    noise=0.1,\n",
    "    random_state=2025\n",
    ")\n",
    "\n",
    "# Draw bootstrap sample\n",
    "bootstrap_data = data.sample(n=1000, replace=True)\n",
    "bootstrap_data = DataGeneration.add_epsilon(bootstrap_data)\n",
    "\n",
    "display(bootstrap_data)\n",
    "\n",
    "X = bootstrap_data.drop(columns=[\"Target\"])\n",
    "y = bootstrap_data[\"Target\"]\n",
    "\n",
    "# Split data\n",
    "X_proper, X_test, y_proper, y_test = train_test_split(X, y, test_size=0.5, random_state=2025)\n",
    "\n",
    "        \n",
    "def to_numpy_safe(x):\n",
    "    return x.to_numpy() if hasattr(x, \"to_numpy\") else x\n",
    "\n",
    "# Convert to numpy arrays if needed\n",
    "X_proper = to_numpy_safe(X_proper)\n",
    "y_proper = to_numpy_safe(y_proper)\n",
    "X_test   = to_numpy_safe(X_test)\n",
    "y_test   = to_numpy_safe(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:419: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_one_minus_h = np.sqrt(1 - h[:-1])\n",
      "/Users/simon/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:420: RuntimeWarning: invalid value encountered in sqrt\n",
      "  A = np.dot(H[-1, :-1], y) / np.sqrt(1 - h[-1])  + (y - H[:-1, :-1] @ y) / sqrt_one_minus_h\n",
      "/Users/simon/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:421: RuntimeWarning: invalid value encountered in sqrt\n",
      "  B = np.sqrt(1 - h[-1]) * np.ones(n-1) + H[-1, :-1] / sqrt_one_minus_h\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "C contains NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(X_test, y_test)):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(i+\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     cpd, precomputed = \u001b[43mcps\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_cpd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_update\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     cps.learn_one(x=x, y=y, precomputed=precomputed)\n\u001b[32m     20\u001b[39m     X_seen = np.vstack([X_seen, x])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:428\u001b[39m, in \u001b[36mKernelRidgePredictionMachine.predict_cpd\u001b[39m\u001b[34m(self, x, return_update, save_time)\u001b[39m\n\u001b[32m    426\u001b[39m C[\u001b[32m0\u001b[39m] = -np.inf\n\u001b[32m    427\u001b[39m C[-\u001b[32m1\u001b[39m] = np.inf\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isnan(C).any(), \u001b[33m\"\u001b[39m\u001b[33mC contains NaN values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m C.sort()\n\u001b[32m    431\u001b[39m time_dict = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: C contains NaN values"
     ]
    }
   ],
   "source": [
    "from online_cp.CPS import NearestNeighboursPredictionMachine\n",
    "from online_cp.CPS import RidgePredictionMachine, KernelRidgePredictionMachine\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "kernel = C(100) * RBF(length_scale=100)\n",
    "cps = KernelRidgePredictionMachine(a=1, kernel=kernel)\n",
    "\n",
    "X_seen = X_proper\n",
    "y_seen = y_proper\n",
    "\n",
    "cps.learn_initial_training_set(X_seen, y_seen)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(X_test, y_test)):\n",
    "    print(i+1)\n",
    "    cpd, precomputed = cps.predict_cpd(x=x, return_update=True)\n",
    "    \n",
    "    cps.learn_one(x=x, y=y, precomputed=precomputed)\n",
    "            \n",
    "    X_seen = np.vstack([X_seen, x])\n",
    "    y_seen = np.append(y_seen, y)\n",
    "    \n",
    "    cps.kernel = C(10) * RBF(length_scale=10)\n",
    "    cps.a = 0.01\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "X_seen = X_proper\n",
    "y_seen = y_proper\n",
    "\n",
    "kernel = C(100) * RBF(length_scale=100)\n",
    "cps = KernelRidgePredictionMachine(a=0.01, kernel=kernel)\n",
    "\n",
    "cps.learn_initial_training_set(X_seen, y_seen)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(X_test, y_test)):\n",
    "    print(i+1)\n",
    "    cpd, precomputed = cps.predict_cpd(x=x, return_update=True)\n",
    "    \n",
    "    kernel = C(100) * RBF(length_scale=100)\n",
    "    cps = KernelRidgePredictionMachine(a=0.01, kernel=kernel)\n",
    "            \n",
    "    X_seen = np.vstack([X_seen, x])\n",
    "    y_seen = np.append(y_seen, y)\n",
    "    \n",
    "    cps.learn_initial_training_set(X_seen, y_seen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seen = np.array([[0.61690403, 0.87447608, 0.46287463, 0.38878679, 0.66070327,\n",
    "        0.00232492, 0.54601537, 0.64432384, 0.68427912, 0.62110265,\n",
    "        0.59712489, 0.6877667 , 0.35055853, 0.58650853, 0.80618439,\n",
    "        0.29815741, 0.735198  , 0.60935794, 0.92569768, 0.11617104],\n",
    "       [0.91579433, 0.02432272, 0.87300042, 0.21273217, 0.23742334,\n",
    "        0.4261802 , 0.62978608, 0.44619609, 0.08229804, 0.99548367,\n",
    "        0.05369916, 0.49441106, 0.08500298, 0.55486127, 0.61009087,\n",
    "        0.85256786, 0.10284571, 0.19523638, 0.33010014, 0.4991184 ],\n",
    "       [0.26023365, 0.07644817, 0.27885393, 0.58315717, 0.49324211,\n",
    "        0.60589993, 0.32866339, 0.83777911, 0.00929254, 0.81334764,\n",
    "        0.74754069, 0.4462899 , 0.46590148, 0.52706113, 0.71749153,\n",
    "        0.63081901, 0.57733303, 0.59577937, 0.11531968, 0.73717042],\n",
    "       [0.45076311, 0.78577283, 0.33347904, 0.85423709, 0.02998891,\n",
    "        0.9413173 , 0.00685749, 0.3835995 , 0.26137372, 0.97404553,\n",
    "        0.018884  , 0.38371018, 0.29799676, 0.04687279, 0.74581966,\n",
    "        0.67774238, 0.43461648, 0.60646479, 0.82850803, 0.58361229],\n",
    "       [0.1975792 , 0.8138122 , 0.81859487, 0.8338643 , 0.70860933,\n",
    "        0.445699  , 0.50907458, 0.28168284, 0.27746932, 0.20906813,\n",
    "        0.58993412, 0.78687081, 0.50354748, 0.62500309, 0.50526637,\n",
    "        0.49038134, 0.23918682, 0.22314794, 0.94578918, 0.34079787],\n",
    "       [0.38876141, 0.50926379, 0.30521151, 0.58781281, 0.45184239,\n",
    "        0.74458284, 0.35833841, 0.27592876, 0.05097637, 0.90305267,\n",
    "        0.71552171, 0.1175358 , 0.80581814, 0.89393874, 0.88091416,\n",
    "        0.63382612, 0.06135225, 0.53220251, 0.15069796, 0.23486857],\n",
    "       [0.03530995, 0.67016732, 0.59231133, 0.95861001, 0.61408845,\n",
    "        0.41297966, 0.54875759, 0.93992849, 0.11189206, 0.55769144,\n",
    "        0.32024245, 0.25934737, 0.68644511, 0.57964617, 0.40294091,\n",
    "        0.88371262, 0.74555981, 0.61305455, 0.77577919, 0.33944854],\n",
    "       [0.46670223, 0.91631504, 0.47087016, 0.18015492, 0.41974278,\n",
    "        0.28584777, 0.84607481, 0.86991923, 0.42356697, 0.15495714,\n",
    "        0.9474776 , 0.8749199 , 0.22955438, 0.79390101, 0.14493672,\n",
    "        0.37139354, 0.65026267, 0.10772185, 0.80760986, 0.49279778],\n",
    "       [0.32678263, 0.9544731 , 0.55092026, 0.38795748, 0.8352388 ,\n",
    "        0.00210927, 0.33727855, 0.26595158, 0.40630893, 0.41415723,\n",
    "        0.0052716 , 0.70843283, 0.41831813, 0.66410819, 0.53172061,\n",
    "        0.83529665, 0.03425966, 0.32402458, 0.78408303, 0.12906995],\n",
    "       [0.49775345, 0.98513313, 0.44786847, 0.97486652, 0.87163405,\n",
    "        0.94023883, 0.18774018, 0.51279296, 0.12047815, 0.94631978,\n",
    "        0.85693063, 0.81514435, 0.80231037, 0.48906128, 0.56876531,\n",
    "        0.99189387, 0.45257105, 0.10296499, 0.74130788, 0.31881868],\n",
    "       [0.57737144, 0.34163632, 0.11251146, 0.93713594, 0.85086369,\n",
    "        0.5350091 , 0.07863634, 0.84201752, 0.59004941, 0.55503539,\n",
    "        0.21264559, 0.31007106, 0.92480549, 0.63227108, 0.37677974,\n",
    "        0.8794214 , 0.17776382, 0.3611084 , 0.74999908, 0.50469715],\n",
    "       [0.44499032, 0.20012612, 0.90493299, 0.32613187, 0.17479493,\n",
    "        0.84286145, 0.4485736 , 0.06452242, 0.51267103, 0.62314745,\n",
    "        0.1255175 , 0.50428765, 0.69856286, 0.59555401, 0.96334816,\n",
    "        0.52138717, 0.91176839, 0.90389543, 0.14513848, 0.68142977],\n",
    "       [0.34648455, 0.27203819, 0.38153724, 0.69674206, 0.49339642,\n",
    "        0.66944446, 0.07806471, 0.10273499, 0.75633336, 0.38110762,\n",
    "        0.13513837, 0.29433877, 0.48950473, 0.54120231, 0.50687474,\n",
    "        0.50381298, 0.47774431, 0.84202576, 0.05316951, 0.27947344],\n",
    "       [0.41746397, 0.36938514, 0.54905781, 0.51777302, 0.42910892,\n",
    "        0.46886277, 0.15823245, 0.36733995, 0.82205883, 0.30137097,\n",
    "        0.84500858, 0.42169599, 0.07131294, 0.17719126, 0.26603235,\n",
    "        0.35291606, 0.2957825 , 0.78882948, 0.88551834, 0.72960781],\n",
    "       [0.64478003, 0.13189925, 0.53105197, 0.53013952, 0.58808762,\n",
    "        0.94376259, 0.4303951 , 0.61367101, 0.04403258, 0.75806092,\n",
    "        0.43616002, 0.93574578, 0.60334329, 0.61923449, 0.38394202,\n",
    "        0.6685584 , 0.85260882, 0.59097694, 0.20951957, 0.0786221 ],\n",
    "       [0.7552315 , 0.4614683 , 0.26357669, 0.09284826, 0.60315382,\n",
    "        0.31369358, 0.32974014, 0.19993976, 0.26682244, 0.20350981,\n",
    "        0.97080258, 0.68341552, 0.37141491, 0.00279919, 0.46767294,\n",
    "        0.08456203, 0.66196791, 0.0471992 , 0.59846991, 0.81362607],\n",
    "       [0.05628668, 0.49687508, 0.29712254, 0.95553429, 0.61047986,\n",
    "        0.08262895, 0.13865336, 0.23443317, 0.12284737, 0.6011743 ,\n",
    "        0.78511282, 0.17012297, 0.31277596, 0.70212678, 0.20009298,\n",
    "        0.50781627, 0.46642926, 0.85430861, 0.86508383, 0.97927647],\n",
    "       [0.11297176, 0.3193713 , 0.69476313, 0.52214091, 0.86160845,\n",
    "        0.04017112, 0.41635022, 0.21291641, 0.47074962, 0.25049169,\n",
    "        0.22260359, 0.32668977, 0.16654484, 0.35965967, 0.69289228,\n",
    "        0.77995073, 0.67096882, 0.68037106, 0.50950037, 0.50659541],\n",
    "       [0.80012599, 0.94870053, 0.59182567, 0.58563817, 0.57371547,\n",
    "        0.31348861, 0.72225411, 0.24891447, 0.31003646, 0.7514819 ,\n",
    "        0.55619309, 0.95382337, 0.83846726, 0.98657012, 0.05288109,\n",
    "        0.6189602 , 0.09206017, 0.25383892, 0.07908283, 0.42123578],\n",
    "       [0.18461492, 0.6433796 , 0.85085628, 0.079005  , 0.03579918,\n",
    "        0.83816129, 0.79430468, 0.98249415, 0.96392254, 0.47197439,\n",
    "        0.40337412, 0.98575147, 0.58227895, 0.47064495, 0.1345221 ,\n",
    "        0.33841849, 0.09543069, 0.72290251, 0.99462444, 0.88337705],\n",
    "       [0.10535415, 0.31401669, 0.89019704, 0.95075513, 0.98326673,\n",
    "        0.85107112, 0.90997526, 0.34222438, 0.5872768 , 0.14046719,\n",
    "        0.47812487, 0.86021296, 0.94306024, 0.93131597, 0.04829842,\n",
    "        0.19960255, 0.91757876, 0.48683352, 0.3372579 , 0.12750855],\n",
    "       [0.189923  , 0.76886905, 0.40357378, 0.72013392, 0.38589263,\n",
    "        0.52346177, 0.05894595, 0.5501359 , 0.21885853, 0.19682074,\n",
    "        0.74164482, 0.480565  , 0.32364022, 0.72340493, 0.50971304,\n",
    "        0.66224582, 0.96321424, 0.53279458, 0.0367493 , 0.47548291],\n",
    "       [0.98184061, 0.82242742, 0.91311657, 0.19905862, 0.8235858 ,\n",
    "        0.86206807, 0.366947  , 0.3621475 , 0.1210519 , 0.96746118,\n",
    "        0.23936093, 0.31172959, 0.04285227, 0.26997335, 0.07257182,\n",
    "        0.63628677, 0.76711326, 0.67381972, 0.78972515, 0.76433807],\n",
    "       [0.87830652, 0.40247937, 0.84492561, 0.54248177, 0.35728949,\n",
    "        0.65521079, 0.23707085, 0.94646998, 0.80260709, 0.0690497 ,\n",
    "        0.46439782, 0.60276499, 0.85467219, 0.62476244, 0.68448804,\n",
    "        0.91727919, 0.56170773, 0.78719359, 0.17924195, 0.04227915],\n",
    "       [0.9164081 , 0.24035337, 0.30209463, 0.21477177, 0.08174764,\n",
    "        0.47510183, 0.4718107 , 0.37238835, 0.08139098, 0.6180113 ,\n",
    "        0.59167568, 0.09392855, 0.95334931, 0.52972731, 0.25937394,\n",
    "        0.60819322, 0.5763105 , 0.65603732, 0.12963586, 0.5527947 ],\n",
    "       [0.73615201, 0.61638444, 0.39035279, 0.55641677, 0.62421441,\n",
    "        0.25802111, 0.93876485, 0.12806208, 0.34472932, 0.21058852,\n",
    "        0.48089751, 0.01945183, 0.68033345, 0.50813111, 0.67703167,\n",
    "        0.20175018, 0.08511787, 0.12465513, 0.61166981, 0.72810863],\n",
    "       [0.38814616, 0.33016759, 0.8347916 , 0.31759653, 0.5394995 ,\n",
    "        0.38193218, 0.6728284 , 0.90742288, 0.96309925, 0.32354187,\n",
    "        0.41797015, 0.85598548, 0.59349483, 0.38311874, 0.05004716,\n",
    "        0.69893119, 0.47553582, 0.45554697, 0.52498651, 0.92197788],\n",
    "       [0.83335522, 0.18028557, 0.83925735, 0.88395057, 0.52634498,\n",
    "        0.75802361, 0.35227691, 0.75901604, 0.36283574, 0.66703115,\n",
    "        0.55953195, 0.41380416, 0.40722059, 0.97550619, 0.82347904,\n",
    "        0.80074657, 0.29144675, 0.16375034, 0.90418439, 0.84182748],\n",
    "       [0.63245495, 0.80247196, 0.80860457, 0.54979344, 0.26280457,\n",
    "        0.99507387, 0.4016898 , 0.79887646, 0.67784378, 0.72811244,\n",
    "        0.48766279, 0.88348734, 0.00211905, 0.35123269, 0.50311107,\n",
    "        0.22038668, 0.79147001, 0.78738263, 0.0484944 , 0.41137662],\n",
    "       [0.62818502, 0.01500276, 0.11845419, 0.73915755, 0.72855623,\n",
    "        0.66182345, 0.64051285, 0.5690818 , 0.31887823, 0.71412555,\n",
    "        0.85200606, 0.46907468, 0.96604888, 0.16398006, 0.31084425,\n",
    "        0.54640548, 0.57224212, 0.63623418, 0.32846183, 0.35210896],\n",
    "       [0.66463358, 0.489743  , 0.45137743, 0.65596187, 0.87487342,\n",
    "        0.96535247, 0.08441544, 0.84104069, 0.91777603, 0.6231457 ,\n",
    "        0.43552652, 0.03328698, 0.87287412, 0.09696855, 0.7248814 ,\n",
    "        0.66677396, 0.16109435, 0.70440369, 0.62900332, 0.7124535 ],\n",
    "       [0.40681158, 0.58735837, 0.6275798 , 0.68556781, 0.16984881,\n",
    "        0.60399803, 0.71763298, 0.50561357, 0.87472338, 0.12593806,\n",
    "        0.10358275, 0.75243194, 0.76829163, 0.08220347, 0.19204259,\n",
    "        0.20552235, 0.59046966, 0.5074028 , 0.11196002, 0.52498511],\n",
    "       [0.46256204, 0.80895007, 0.07956222, 0.34577538, 0.4359663 ,\n",
    "        0.59042979, 0.7997986 , 0.41417156, 0.98475942, 0.20623434,\n",
    "        0.95571796, 0.54303571, 0.98554355, 0.70865926, 0.80314321,\n",
    "        0.75906356, 0.6162506 , 0.69717804, 0.06130025, 0.82293526],\n",
    "       [0.65224292, 0.69759562, 0.38363283, 0.41599009, 0.50379321,\n",
    "        0.08028608, 0.13806171, 0.72361662, 0.01821525, 0.02295151,\n",
    "        0.90915442, 0.82481228, 0.34934783, 0.56330673, 0.82881332,\n",
    "        0.61034537, 0.02458505, 0.33239802, 0.46095784, 0.12674915],\n",
    "       [0.81891762, 0.17742008, 0.5583408 , 0.67670142, 0.06625006,\n",
    "        0.77871585, 0.99401999, 0.18710728, 0.12540084, 0.28348024,\n",
    "        0.84032088, 0.07620544, 0.05674359, 0.85768277, 0.53645601,\n",
    "        0.01023173, 0.7079834 , 0.9916835 , 0.73517333, 0.26736103],\n",
    "       [0.99995419, 0.98983132, 0.92818045, 0.09891396, 0.71226002,\n",
    "        0.8487543 , 0.78082758, 0.13319967, 0.93595417, 0.07502853,\n",
    "        0.18302575, 0.71907877, 0.2610095 , 0.51160147, 0.55268635,\n",
    "        0.42863181, 0.88749287, 0.29829858, 0.45829795, 0.60283157],\n",
    "       [0.91784771, 0.62774378, 0.08959139, 0.12344046, 0.94897967,\n",
    "        0.98446017, 0.10304698, 0.69274853, 0.65948703, 0.96761688,\n",
    "        0.84741886, 0.71584026, 0.08163966, 0.12905297, 0.40769082,\n",
    "        0.12751238, 0.31982213, 0.12098797, 0.42515927, 0.14501096],\n",
    "       [0.50014376, 0.25764066, 0.89321616, 0.42712926, 0.0554846 ,\n",
    "        0.95114228, 0.71358808, 0.28102892, 0.16923638, 0.07674369,\n",
    "        0.81212113, 0.36325585, 0.86309813, 0.71734953, 0.94592495,\n",
    "        0.97832059, 0.99662547, 0.27319607, 0.45119052, 0.96076004],\n",
    "       [0.90253823, 0.24733245, 0.32683554, 0.52682568, 0.49748272,\n",
    "        0.12236442, 0.03298476, 0.20974979, 0.16296402, 0.58427078,\n",
    "        0.26675697, 0.46668716, 0.84086689, 0.64536565, 0.3106762 ,\n",
    "        0.11220032, 0.8994947 , 0.73787026, 0.6554433 , 0.6753808 ],\n",
    "       [0.18567906, 0.00399292, 0.47641247, 0.91865786, 0.41887556,\n",
    "        0.70834108, 0.17959301, 0.4380631 , 0.67724269, 0.69667343,\n",
    "        0.72800649, 0.17028013, 0.9146416 , 0.92159125, 0.41425331,\n",
    "        0.4006198 , 0.36910244, 0.63384678, 0.84616134, 0.17025744],\n",
    "       [0.92531473, 0.1655071 , 0.51796206, 0.21671123, 0.54801563,\n",
    "        0.27716926, 0.14992817, 0.05253494, 0.66211856, 0.68645151,\n",
    "        0.78970834, 0.35615426, 0.49116681, 0.94477949, 0.93507594,\n",
    "        0.47452467, 0.70245381, 0.43934428, 0.95295703, 0.4187147 ],\n",
    "       [0.33515453, 0.10705191, 0.25710262, 0.36302646, 0.82550822,\n",
    "        0.51990847, 0.72108586, 0.74177152, 0.11450249, 0.89406315,\n",
    "        0.34797566, 0.895625  , 0.46165193, 0.2135426 , 0.53488725,\n",
    "        0.72321418, 0.7878882 , 0.30746976, 0.76429345, 0.73536041]])\n",
    "y_seen = np.array([0.57218823, 0.20232463, 0.31767826, 0.62873191, 0.64141939,\n",
    "       0.49516018, 0.4578338 , 0.46423245, 0.55617846, 0.84011891,\n",
    "       0.78049052, 0.33286834, 0.4194628 , 0.39678775, 0.35077619,\n",
    "       0.47188588, 0.48166685, 0.37978283, 0.53653371, 0.22448738,\n",
    "       0.63234304, 0.45718868, 0.51364395, 0.63637147, 0.3139276 ,\n",
    "       0.64666755, 0.40074023, 0.63491258, 0.63916471, 0.48231435,\n",
    "       0.66133472, 0.50648569, 0.62976103, 0.57465927, 0.37493874,\n",
    "       0.27508023, 0.64724572, 0.37859445, 0.49631768, 0.37113892,\n",
    "       0.31092492, 0.32695493])\n",
    "x = np.array([0.09842664, 0.91452938, 0.42056915, 0.46360808, 0.65245194,\n",
    "       0.83982535, 0.78429744, 0.49834649, 0.28574984, 0.87174272,\n",
    "       0.61163489, 0.17329679, 0.46724292, 0.87860093, 0.52903206,\n",
    "       0.24919905, 0.98664782, 0.51081124, 0.82706065, 0.17630974])\n",
    "y = np.float64(0.3558477174746414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(10) * RBF(length_scale=100)\n",
    "cps = KernelRidgePredictionMachine(a=0.01, kernel=kernel)\n",
    "\n",
    "cps.learn_initial_training_set(X_seen, y_seen)\n",
    "\n",
    "cpd, precomputed = cps.predict_cpd(x=x, return_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
