{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add it to sys.path if not already added\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_11</th>\n",
       "      <th>Feature_12</th>\n",
       "      <th>Feature_13</th>\n",
       "      <th>Feature_14</th>\n",
       "      <th>Feature_15</th>\n",
       "      <th>Feature_16</th>\n",
       "      <th>Feature_17</th>\n",
       "      <th>Feature_18</th>\n",
       "      <th>Feature_19</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>0.283209</td>\n",
       "      <td>0.619017</td>\n",
       "      <td>0.964726</td>\n",
       "      <td>0.826335</td>\n",
       "      <td>0.391404</td>\n",
       "      <td>0.921496</td>\n",
       "      <td>0.243513</td>\n",
       "      <td>0.771115</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.268888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922848</td>\n",
       "      <td>0.842636</td>\n",
       "      <td>0.028551</td>\n",
       "      <td>0.491376</td>\n",
       "      <td>0.128042</td>\n",
       "      <td>0.478260</td>\n",
       "      <td>0.432899</td>\n",
       "      <td>0.724028</td>\n",
       "      <td>0.742700</td>\n",
       "      <td>0.677966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>0.477026</td>\n",
       "      <td>0.621602</td>\n",
       "      <td>0.395473</td>\n",
       "      <td>0.092578</td>\n",
       "      <td>0.711920</td>\n",
       "      <td>0.873432</td>\n",
       "      <td>0.049040</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>0.731535</td>\n",
       "      <td>0.777246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685370</td>\n",
       "      <td>0.708719</td>\n",
       "      <td>0.279626</td>\n",
       "      <td>0.951546</td>\n",
       "      <td>0.180196</td>\n",
       "      <td>0.377338</td>\n",
       "      <td>0.909251</td>\n",
       "      <td>0.012296</td>\n",
       "      <td>0.526554</td>\n",
       "      <td>0.420197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7479</th>\n",
       "      <td>0.805700</td>\n",
       "      <td>0.465609</td>\n",
       "      <td>0.635555</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.417074</td>\n",
       "      <td>0.400283</td>\n",
       "      <td>0.807253</td>\n",
       "      <td>0.539793</td>\n",
       "      <td>0.991637</td>\n",
       "      <td>0.266629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286673</td>\n",
       "      <td>0.589966</td>\n",
       "      <td>0.985275</td>\n",
       "      <td>0.857607</td>\n",
       "      <td>0.638241</td>\n",
       "      <td>0.615280</td>\n",
       "      <td>0.877771</td>\n",
       "      <td>0.841870</td>\n",
       "      <td>0.787572</td>\n",
       "      <td>0.573692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>0.320210</td>\n",
       "      <td>0.918319</td>\n",
       "      <td>0.895457</td>\n",
       "      <td>0.865465</td>\n",
       "      <td>0.530941</td>\n",
       "      <td>0.720140</td>\n",
       "      <td>0.239639</td>\n",
       "      <td>0.811441</td>\n",
       "      <td>0.697780</td>\n",
       "      <td>0.861342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471751</td>\n",
       "      <td>0.411969</td>\n",
       "      <td>0.009063</td>\n",
       "      <td>0.572650</td>\n",
       "      <td>0.775382</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.692800</td>\n",
       "      <td>0.771086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>0.101315</td>\n",
       "      <td>0.991698</td>\n",
       "      <td>0.405772</td>\n",
       "      <td>0.146743</td>\n",
       "      <td>0.560949</td>\n",
       "      <td>0.683020</td>\n",
       "      <td>0.143506</td>\n",
       "      <td>0.088906</td>\n",
       "      <td>0.337773</td>\n",
       "      <td>0.564731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741200</td>\n",
       "      <td>0.293507</td>\n",
       "      <td>0.919180</td>\n",
       "      <td>0.579853</td>\n",
       "      <td>0.896566</td>\n",
       "      <td>0.760269</td>\n",
       "      <td>0.071287</td>\n",
       "      <td>0.807472</td>\n",
       "      <td>0.285211</td>\n",
       "      <td>0.240257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.759154</td>\n",
       "      <td>0.751253</td>\n",
       "      <td>0.120915</td>\n",
       "      <td>0.951917</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>0.596132</td>\n",
       "      <td>0.540771</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>0.685526</td>\n",
       "      <td>0.493089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447714</td>\n",
       "      <td>0.926388</td>\n",
       "      <td>0.600240</td>\n",
       "      <td>0.594252</td>\n",
       "      <td>0.277319</td>\n",
       "      <td>0.322593</td>\n",
       "      <td>0.638388</td>\n",
       "      <td>0.295163</td>\n",
       "      <td>0.892707</td>\n",
       "      <td>0.898353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>0.168766</td>\n",
       "      <td>0.407459</td>\n",
       "      <td>0.239170</td>\n",
       "      <td>0.289375</td>\n",
       "      <td>0.692930</td>\n",
       "      <td>0.684785</td>\n",
       "      <td>0.254688</td>\n",
       "      <td>0.135723</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.611462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857818</td>\n",
       "      <td>0.374393</td>\n",
       "      <td>0.225887</td>\n",
       "      <td>0.023514</td>\n",
       "      <td>0.820358</td>\n",
       "      <td>0.492798</td>\n",
       "      <td>0.548057</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>0.032930</td>\n",
       "      <td>0.316051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>0.157857</td>\n",
       "      <td>0.947721</td>\n",
       "      <td>0.885448</td>\n",
       "      <td>0.573501</td>\n",
       "      <td>0.879746</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.946338</td>\n",
       "      <td>0.700180</td>\n",
       "      <td>0.635058</td>\n",
       "      <td>0.357432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100378</td>\n",
       "      <td>0.553785</td>\n",
       "      <td>0.521723</td>\n",
       "      <td>0.531864</td>\n",
       "      <td>0.985542</td>\n",
       "      <td>0.914115</td>\n",
       "      <td>0.194652</td>\n",
       "      <td>0.284678</td>\n",
       "      <td>0.319803</td>\n",
       "      <td>0.603940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0.745270</td>\n",
       "      <td>0.859352</td>\n",
       "      <td>0.244475</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>0.960137</td>\n",
       "      <td>0.247874</td>\n",
       "      <td>0.209637</td>\n",
       "      <td>0.153665</td>\n",
       "      <td>0.172023</td>\n",
       "      <td>0.983704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385766</td>\n",
       "      <td>0.209484</td>\n",
       "      <td>0.121910</td>\n",
       "      <td>0.898386</td>\n",
       "      <td>0.318847</td>\n",
       "      <td>0.859157</td>\n",
       "      <td>0.907809</td>\n",
       "      <td>0.873120</td>\n",
       "      <td>0.460668</td>\n",
       "      <td>0.521911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>0.248305</td>\n",
       "      <td>0.708198</td>\n",
       "      <td>0.351671</td>\n",
       "      <td>0.756312</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.378972</td>\n",
       "      <td>0.962985</td>\n",
       "      <td>0.883510</td>\n",
       "      <td>0.874491</td>\n",
       "      <td>0.646453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247545</td>\n",
       "      <td>0.600170</td>\n",
       "      <td>0.799852</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.374053</td>\n",
       "      <td>0.443902</td>\n",
       "      <td>0.755895</td>\n",
       "      <td>0.616856</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.441021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "6892   0.283209   0.619017   0.964726   0.826335   0.391404   0.921496   \n",
       "2822   0.477026   0.621602   0.395473   0.092578   0.711920   0.873432   \n",
       "7479   0.805700   0.465609   0.635555   0.500600   0.417074   0.400283   \n",
       "6011   0.320210   0.918319   0.895457   0.865465   0.530941   0.720140   \n",
       "5980   0.101315   0.991698   0.405772   0.146743   0.560949   0.683020   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "747    0.759154   0.751253   0.120915   0.951917   0.699605   0.596132   \n",
       "1621   0.168766   0.407459   0.239170   0.289375   0.692930   0.684785   \n",
       "5099   0.157857   0.947721   0.885448   0.573501   0.879746   0.012183   \n",
       "908    0.745270   0.859352   0.244475   0.035649   0.960137   0.247874   \n",
       "1315   0.248305   0.708198   0.351671   0.756312   0.004993   0.378972   \n",
       "\n",
       "      Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_11  Feature_12  \\\n",
       "6892   0.243513   0.771115   0.014833   0.268888  ...    0.922848    0.842636   \n",
       "2822   0.049040   0.024511   0.731535   0.777246  ...    0.685370    0.708719   \n",
       "7479   0.807253   0.539793   0.991637   0.266629  ...    0.286673    0.589966   \n",
       "6011   0.239639   0.811441   0.697780   0.861342  ...    0.471751    0.411969   \n",
       "5980   0.143506   0.088906   0.337773   0.564731  ...    0.741200    0.293507   \n",
       "...         ...        ...        ...        ...  ...         ...         ...   \n",
       "747    0.540771   0.239865   0.685526   0.493089  ...    0.447714    0.926388   \n",
       "1621   0.254688   0.135723   0.002816   0.611462  ...    0.857818    0.374393   \n",
       "5099   0.946338   0.700180   0.635058   0.357432  ...    0.100378    0.553785   \n",
       "908    0.209637   0.153665   0.172023   0.983704  ...    0.385766    0.209484   \n",
       "1315   0.962985   0.883510   0.874491   0.646453  ...    0.247545    0.600170   \n",
       "\n",
       "      Feature_13  Feature_14  Feature_15  Feature_16  Feature_17  Feature_18  \\\n",
       "6892    0.028551    0.491376    0.128042    0.478260    0.432899    0.724028   \n",
       "2822    0.279626    0.951546    0.180196    0.377338    0.909251    0.012296   \n",
       "7479    0.985275    0.857607    0.638241    0.615280    0.877771    0.841870   \n",
       "6011    0.009063    0.572650    0.775382    0.563651    0.529173    0.771919   \n",
       "5980    0.919180    0.579853    0.896566    0.760269    0.071287    0.807472   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "747     0.600240    0.594252    0.277319    0.322593    0.638388    0.295163   \n",
       "1621    0.225887    0.023514    0.820358    0.492798    0.548057    0.009532   \n",
       "5099    0.521723    0.531864    0.985542    0.914115    0.194652    0.284678   \n",
       "908     0.121910    0.898386    0.318847    0.859157    0.907809    0.873120   \n",
       "1315    0.799852    0.005930    0.374053    0.443902    0.755895    0.616856   \n",
       "\n",
       "      Feature_19    Target  \n",
       "6892    0.742700  0.677966  \n",
       "2822    0.526554  0.420197  \n",
       "7479    0.787572  0.573692  \n",
       "6011    0.692800  0.771086  \n",
       "5980    0.285211  0.240257  \n",
       "...          ...       ...  \n",
       "747     0.892707  0.898353  \n",
       "1621    0.032930  0.316051  \n",
       "5099    0.319803  0.603940  \n",
       "908     0.460668  0.521911  \n",
       "1315    0.067003  0.441021  \n",
       "\n",
       "[1000 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.functions.data_generation import DataGeneration\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = DataGeneration.generate_data(\n",
    "    n_samples=10000,\n",
    "    n_features=20,\n",
    "    n_informative=4,\n",
    "    relationship='friedman1',\n",
    "    noise=0.1,\n",
    "    random_state=2025\n",
    ")\n",
    "\n",
    "# Draw bootstrap sample\n",
    "bootstrap_data = data.sample(n=1000, replace=True)\n",
    "bootstrap_data = DataGeneration.add_epsilon(bootstrap_data)\n",
    "\n",
    "display(bootstrap_data)\n",
    "\n",
    "X = bootstrap_data.drop(columns=[\"Target\"])\n",
    "y = bootstrap_data[\"Target\"]\n",
    "\n",
    "# Split data\n",
    "X_proper, X_test, y_proper, y_test = train_test_split(X, y, test_size=0.5, random_state=2025)\n",
    "\n",
    "        \n",
    "def to_numpy_safe(x):\n",
    "    return x.to_numpy() if hasattr(x, \"to_numpy\") else x\n",
    "\n",
    "# Convert to numpy arrays if needed\n",
    "X_proper = to_numpy_safe(X_proper)\n",
    "y_proper = to_numpy_safe(y_proper)\n",
    "X_test   = to_numpy_safe(X_test)\n",
    "y_test   = to_numpy_safe(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:419: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_one_minus_h = np.sqrt(1 - h[:-1])\n",
      "/Users/simon/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:420: RuntimeWarning: invalid value encountered in sqrt\n",
      "  A = np.dot(H[-1, :-1], y) / np.sqrt(1 - h[-1])  + (y - H[:-1, :-1] @ y) / sqrt_one_minus_h\n",
      "/Users/simon/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:421: RuntimeWarning: invalid value encountered in sqrt\n",
      "  B = np.sqrt(1 - h[-1]) * np.ones(n-1) + H[-1, :-1] / sqrt_one_minus_h\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "C contains NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(X_test, y_test)):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(i+\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     cpd, precomputed = \u001b[43mcps\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_cpd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_update\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     cps.learn_one(x=x, y=y, precomputed=precomputed)\n\u001b[32m     20\u001b[39m     X_seen = np.vstack([X_seen, x])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:428\u001b[39m, in \u001b[36mKernelRidgePredictionMachine.predict_cpd\u001b[39m\u001b[34m(self, x, return_update, save_time)\u001b[39m\n\u001b[32m    426\u001b[39m C[\u001b[32m0\u001b[39m] = -np.inf\n\u001b[32m    427\u001b[39m C[-\u001b[32m1\u001b[39m] = np.inf\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isnan(C).any(), \u001b[33m\"\u001b[39m\u001b[33mC contains NaN values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m C.sort()\n\u001b[32m    431\u001b[39m time_dict = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: C contains NaN values"
     ]
    }
   ],
   "source": [
    "from online_cp.CPS import NearestNeighboursPredictionMachine\n",
    "from online_cp.CPS import RidgePredictionMachine, KernelRidgePredictionMachine\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "kernel = C(100) * RBF(length_scale=100)\n",
    "cps = KernelRidgePredictionMachine(a=1, kernel=kernel)\n",
    "\n",
    "X_seen = X_proper\n",
    "y_seen = y_proper\n",
    "\n",
    "cps.learn_initial_training_set(X_seen, y_seen)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(X_test, y_test)):\n",
    "    print(i+1)\n",
    "    cpd, precomputed = cps.predict_cpd(x=x, return_update=True)\n",
    "    \n",
    "    cps.learn_one(x=x, y=y, precomputed=precomputed)\n",
    "            \n",
    "    X_seen = np.vstack([X_seen, x])\n",
    "    y_seen = np.append(y_seen, y)\n",
    "    \n",
    "    cps.kernel = C(10) * RBF(length_scale=10)\n",
    "    cps.a = 0.01\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "C contains NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(X_test, y_test)):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(i+\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     cpd, precomputed = \u001b[43mcps\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_cpd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_update\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     kernel = C(\u001b[32m100\u001b[39m) * RBF(length_scale=\u001b[32m100\u001b[39m)\n\u001b[32m      8\u001b[39m     cps = KernelRidgePredictionMachine(a=\u001b[32m0.01\u001b[39m, kernel=kernel)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Conformal-Predictive-Decision-Making/.venv/lib/python3.13/site-packages/online_cp/CPS.py:428\u001b[39m, in \u001b[36mKernelRidgePredictionMachine.predict_cpd\u001b[39m\u001b[34m(self, x, return_update, save_time)\u001b[39m\n\u001b[32m    426\u001b[39m C[\u001b[32m0\u001b[39m] = -np.inf\n\u001b[32m    427\u001b[39m C[-\u001b[32m1\u001b[39m] = np.inf\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isnan(C).any(), \u001b[33m\"\u001b[39m\u001b[33mC contains NaN values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m C.sort()\n\u001b[32m    431\u001b[39m time_dict = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: C contains NaN values"
     ]
    }
   ],
   "source": [
    "X_seen = X_proper\n",
    "y_seen = y_proper\n",
    "\n",
    "kernel = C(100) * RBF(length_scale=100)\n",
    "cps = KernelRidgePredictionMachine(a=0.01, kernel=kernel)\n",
    "\n",
    "for i, (x, y) in enumerate(zip(X_test, y_test)):\n",
    "    print(i+1)\n",
    "    cpd, precomputed = cps.predict_cpd(x=x, return_update=True)\n",
    "    \n",
    "    kernel = C(100) * RBF(length_scale=100)\n",
    "    cps = KernelRidgePredictionMachine(a=0.01, kernel=kernel)\n",
    "            \n",
    "    X_seen = np.vstack([X_seen, x])\n",
    "    y_seen = np.append(y_seen, y)\n",
    "    \n",
    "    cps.learn_initial_training_set(X_seen, y_seen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seen = np.array([[0.61690403, 0.87447608, 0.46287463, 0.38878679, 0.66070327,\n",
    "        0.00232492, 0.54601537, 0.64432384, 0.68427912, 0.62110265,\n",
    "        0.59712489, 0.6877667 , 0.35055853, 0.58650853, 0.80618439,\n",
    "        0.29815741, 0.735198  , 0.60935794, 0.92569768, 0.11617104],\n",
    "       [0.91579433, 0.02432272, 0.87300042, 0.21273217, 0.23742334,\n",
    "        0.4261802 , 0.62978608, 0.44619609, 0.08229804, 0.99548367,\n",
    "        0.05369916, 0.49441106, 0.08500298, 0.55486127, 0.61009087,\n",
    "        0.85256786, 0.10284571, 0.19523638, 0.33010014, 0.4991184 ],\n",
    "       [0.26023365, 0.07644817, 0.27885393, 0.58315717, 0.49324211,\n",
    "        0.60589993, 0.32866339, 0.83777911, 0.00929254, 0.81334764,\n",
    "        0.74754069, 0.4462899 , 0.46590148, 0.52706113, 0.71749153,\n",
    "        0.63081901, 0.57733303, 0.59577937, 0.11531968, 0.73717042],\n",
    "       [0.45076311, 0.78577283, 0.33347904, 0.85423709, 0.02998891,\n",
    "        0.9413173 , 0.00685749, 0.3835995 , 0.26137372, 0.97404553,\n",
    "        0.018884  , 0.38371018, 0.29799676, 0.04687279, 0.74581966,\n",
    "        0.67774238, 0.43461648, 0.60646479, 0.82850803, 0.58361229],\n",
    "       [0.1975792 , 0.8138122 , 0.81859487, 0.8338643 , 0.70860933,\n",
    "        0.445699  , 0.50907458, 0.28168284, 0.27746932, 0.20906813,\n",
    "        0.58993412, 0.78687081, 0.50354748, 0.62500309, 0.50526637,\n",
    "        0.49038134, 0.23918682, 0.22314794, 0.94578918, 0.34079787],\n",
    "       [0.38876141, 0.50926379, 0.30521151, 0.58781281, 0.45184239,\n",
    "        0.74458284, 0.35833841, 0.27592876, 0.05097637, 0.90305267,\n",
    "        0.71552171, 0.1175358 , 0.80581814, 0.89393874, 0.88091416,\n",
    "        0.63382612, 0.06135225, 0.53220251, 0.15069796, 0.23486857],\n",
    "       [0.03530995, 0.67016732, 0.59231133, 0.95861001, 0.61408845,\n",
    "        0.41297966, 0.54875759, 0.93992849, 0.11189206, 0.55769144,\n",
    "        0.32024245, 0.25934737, 0.68644511, 0.57964617, 0.40294091,\n",
    "        0.88371262, 0.74555981, 0.61305455, 0.77577919, 0.33944854],\n",
    "       [0.46670223, 0.91631504, 0.47087016, 0.18015492, 0.41974278,\n",
    "        0.28584777, 0.84607481, 0.86991923, 0.42356697, 0.15495714,\n",
    "        0.9474776 , 0.8749199 , 0.22955438, 0.79390101, 0.14493672,\n",
    "        0.37139354, 0.65026267, 0.10772185, 0.80760986, 0.49279778],\n",
    "       [0.32678263, 0.9544731 , 0.55092026, 0.38795748, 0.8352388 ,\n",
    "        0.00210927, 0.33727855, 0.26595158, 0.40630893, 0.41415723,\n",
    "        0.0052716 , 0.70843283, 0.41831813, 0.66410819, 0.53172061,\n",
    "        0.83529665, 0.03425966, 0.32402458, 0.78408303, 0.12906995],\n",
    "       [0.49775345, 0.98513313, 0.44786847, 0.97486652, 0.87163405,\n",
    "        0.94023883, 0.18774018, 0.51279296, 0.12047815, 0.94631978,\n",
    "        0.85693063, 0.81514435, 0.80231037, 0.48906128, 0.56876531,\n",
    "        0.99189387, 0.45257105, 0.10296499, 0.74130788, 0.31881868],\n",
    "       [0.57737144, 0.34163632, 0.11251146, 0.93713594, 0.85086369,\n",
    "        0.5350091 , 0.07863634, 0.84201752, 0.59004941, 0.55503539,\n",
    "        0.21264559, 0.31007106, 0.92480549, 0.63227108, 0.37677974,\n",
    "        0.8794214 , 0.17776382, 0.3611084 , 0.74999908, 0.50469715],\n",
    "       [0.44499032, 0.20012612, 0.90493299, 0.32613187, 0.17479493,\n",
    "        0.84286145, 0.4485736 , 0.06452242, 0.51267103, 0.62314745,\n",
    "        0.1255175 , 0.50428765, 0.69856286, 0.59555401, 0.96334816,\n",
    "        0.52138717, 0.91176839, 0.90389543, 0.14513848, 0.68142977],\n",
    "       [0.34648455, 0.27203819, 0.38153724, 0.69674206, 0.49339642,\n",
    "        0.66944446, 0.07806471, 0.10273499, 0.75633336, 0.38110762,\n",
    "        0.13513837, 0.29433877, 0.48950473, 0.54120231, 0.50687474,\n",
    "        0.50381298, 0.47774431, 0.84202576, 0.05316951, 0.27947344],\n",
    "       [0.41746397, 0.36938514, 0.54905781, 0.51777302, 0.42910892,\n",
    "        0.46886277, 0.15823245, 0.36733995, 0.82205883, 0.30137097,\n",
    "        0.84500858, 0.42169599, 0.07131294, 0.17719126, 0.26603235,\n",
    "        0.35291606, 0.2957825 , 0.78882948, 0.88551834, 0.72960781],\n",
    "       [0.64478003, 0.13189925, 0.53105197, 0.53013952, 0.58808762,\n",
    "        0.94376259, 0.4303951 , 0.61367101, 0.04403258, 0.75806092,\n",
    "        0.43616002, 0.93574578, 0.60334329, 0.61923449, 0.38394202,\n",
    "        0.6685584 , 0.85260882, 0.59097694, 0.20951957, 0.0786221 ],\n",
    "       [0.7552315 , 0.4614683 , 0.26357669, 0.09284826, 0.60315382,\n",
    "        0.31369358, 0.32974014, 0.19993976, 0.26682244, 0.20350981,\n",
    "        0.97080258, 0.68341552, 0.37141491, 0.00279919, 0.46767294,\n",
    "        0.08456203, 0.66196791, 0.0471992 , 0.59846991, 0.81362607],\n",
    "       [0.05628668, 0.49687508, 0.29712254, 0.95553429, 0.61047986,\n",
    "        0.08262895, 0.13865336, 0.23443317, 0.12284737, 0.6011743 ,\n",
    "        0.78511282, 0.17012297, 0.31277596, 0.70212678, 0.20009298,\n",
    "        0.50781627, 0.46642926, 0.85430861, 0.86508383, 0.97927647],\n",
    "       [0.11297176, 0.3193713 , 0.69476313, 0.52214091, 0.86160845,\n",
    "        0.04017112, 0.41635022, 0.21291641, 0.47074962, 0.25049169,\n",
    "        0.22260359, 0.32668977, 0.16654484, 0.35965967, 0.69289228,\n",
    "        0.77995073, 0.67096882, 0.68037106, 0.50950037, 0.50659541],\n",
    "       [0.80012599, 0.94870053, 0.59182567, 0.58563817, 0.57371547,\n",
    "        0.31348861, 0.72225411, 0.24891447, 0.31003646, 0.7514819 ,\n",
    "        0.55619309, 0.95382337, 0.83846726, 0.98657012, 0.05288109,\n",
    "        0.6189602 , 0.09206017, 0.25383892, 0.07908283, 0.42123578],\n",
    "       [0.18461492, 0.6433796 , 0.85085628, 0.079005  , 0.03579918,\n",
    "        0.83816129, 0.79430468, 0.98249415, 0.96392254, 0.47197439,\n",
    "        0.40337412, 0.98575147, 0.58227895, 0.47064495, 0.1345221 ,\n",
    "        0.33841849, 0.09543069, 0.72290251, 0.99462444, 0.88337705],\n",
    "       [0.10535415, 0.31401669, 0.89019704, 0.95075513, 0.98326673,\n",
    "        0.85107112, 0.90997526, 0.34222438, 0.5872768 , 0.14046719,\n",
    "        0.47812487, 0.86021296, 0.94306024, 0.93131597, 0.04829842,\n",
    "        0.19960255, 0.91757876, 0.48683352, 0.3372579 , 0.12750855],\n",
    "       [0.189923  , 0.76886905, 0.40357378, 0.72013392, 0.38589263,\n",
    "        0.52346177, 0.05894595, 0.5501359 , 0.21885853, 0.19682074,\n",
    "        0.74164482, 0.480565  , 0.32364022, 0.72340493, 0.50971304,\n",
    "        0.66224582, 0.96321424, 0.53279458, 0.0367493 , 0.47548291],\n",
    "       [0.98184061, 0.82242742, 0.91311657, 0.19905862, 0.8235858 ,\n",
    "        0.86206807, 0.366947  , 0.3621475 , 0.1210519 , 0.96746118,\n",
    "        0.23936093, 0.31172959, 0.04285227, 0.26997335, 0.07257182,\n",
    "        0.63628677, 0.76711326, 0.67381972, 0.78972515, 0.76433807],\n",
    "       [0.87830652, 0.40247937, 0.84492561, 0.54248177, 0.35728949,\n",
    "        0.65521079, 0.23707085, 0.94646998, 0.80260709, 0.0690497 ,\n",
    "        0.46439782, 0.60276499, 0.85467219, 0.62476244, 0.68448804,\n",
    "        0.91727919, 0.56170773, 0.78719359, 0.17924195, 0.04227915],\n",
    "       [0.9164081 , 0.24035337, 0.30209463, 0.21477177, 0.08174764,\n",
    "        0.47510183, 0.4718107 , 0.37238835, 0.08139098, 0.6180113 ,\n",
    "        0.59167568, 0.09392855, 0.95334931, 0.52972731, 0.25937394,\n",
    "        0.60819322, 0.5763105 , 0.65603732, 0.12963586, 0.5527947 ],\n",
    "       [0.73615201, 0.61638444, 0.39035279, 0.55641677, 0.62421441,\n",
    "        0.25802111, 0.93876485, 0.12806208, 0.34472932, 0.21058852,\n",
    "        0.48089751, 0.01945183, 0.68033345, 0.50813111, 0.67703167,\n",
    "        0.20175018, 0.08511787, 0.12465513, 0.61166981, 0.72810863],\n",
    "       [0.38814616, 0.33016759, 0.8347916 , 0.31759653, 0.5394995 ,\n",
    "        0.38193218, 0.6728284 , 0.90742288, 0.96309925, 0.32354187,\n",
    "        0.41797015, 0.85598548, 0.59349483, 0.38311874, 0.05004716,\n",
    "        0.69893119, 0.47553582, 0.45554697, 0.52498651, 0.92197788],\n",
    "       [0.83335522, 0.18028557, 0.83925735, 0.88395057, 0.52634498,\n",
    "        0.75802361, 0.35227691, 0.75901604, 0.36283574, 0.66703115,\n",
    "        0.55953195, 0.41380416, 0.40722059, 0.97550619, 0.82347904,\n",
    "        0.80074657, 0.29144675, 0.16375034, 0.90418439, 0.84182748],\n",
    "       [0.63245495, 0.80247196, 0.80860457, 0.54979344, 0.26280457,\n",
    "        0.99507387, 0.4016898 , 0.79887646, 0.67784378, 0.72811244,\n",
    "        0.48766279, 0.88348734, 0.00211905, 0.35123269, 0.50311107,\n",
    "        0.22038668, 0.79147001, 0.78738263, 0.0484944 , 0.41137662],\n",
    "       [0.62818502, 0.01500276, 0.11845419, 0.73915755, 0.72855623,\n",
    "        0.66182345, 0.64051285, 0.5690818 , 0.31887823, 0.71412555,\n",
    "        0.85200606, 0.46907468, 0.96604888, 0.16398006, 0.31084425,\n",
    "        0.54640548, 0.57224212, 0.63623418, 0.32846183, 0.35210896],\n",
    "       [0.66463358, 0.489743  , 0.45137743, 0.65596187, 0.87487342,\n",
    "        0.96535247, 0.08441544, 0.84104069, 0.91777603, 0.6231457 ,\n",
    "        0.43552652, 0.03328698, 0.87287412, 0.09696855, 0.7248814 ,\n",
    "        0.66677396, 0.16109435, 0.70440369, 0.62900332, 0.7124535 ],\n",
    "       [0.40681158, 0.58735837, 0.6275798 , 0.68556781, 0.16984881,\n",
    "        0.60399803, 0.71763298, 0.50561357, 0.87472338, 0.12593806,\n",
    "        0.10358275, 0.75243194, 0.76829163, 0.08220347, 0.19204259,\n",
    "        0.20552235, 0.59046966, 0.5074028 , 0.11196002, 0.52498511],\n",
    "       [0.46256204, 0.80895007, 0.07956222, 0.34577538, 0.4359663 ,\n",
    "        0.59042979, 0.7997986 , 0.41417156, 0.98475942, 0.20623434,\n",
    "        0.95571796, 0.54303571, 0.98554355, 0.70865926, 0.80314321,\n",
    "        0.75906356, 0.6162506 , 0.69717804, 0.06130025, 0.82293526],\n",
    "       [0.65224292, 0.69759562, 0.38363283, 0.41599009, 0.50379321,\n",
    "        0.08028608, 0.13806171, 0.72361662, 0.01821525, 0.02295151,\n",
    "        0.90915442, 0.82481228, 0.34934783, 0.56330673, 0.82881332,\n",
    "        0.61034537, 0.02458505, 0.33239802, 0.46095784, 0.12674915],\n",
    "       [0.81891762, 0.17742008, 0.5583408 , 0.67670142, 0.06625006,\n",
    "        0.77871585, 0.99401999, 0.18710728, 0.12540084, 0.28348024,\n",
    "        0.84032088, 0.07620544, 0.05674359, 0.85768277, 0.53645601,\n",
    "        0.01023173, 0.7079834 , 0.9916835 , 0.73517333, 0.26736103],\n",
    "       [0.99995419, 0.98983132, 0.92818045, 0.09891396, 0.71226002,\n",
    "        0.8487543 , 0.78082758, 0.13319967, 0.93595417, 0.07502853,\n",
    "        0.18302575, 0.71907877, 0.2610095 , 0.51160147, 0.55268635,\n",
    "        0.42863181, 0.88749287, 0.29829858, 0.45829795, 0.60283157],\n",
    "       [0.91784771, 0.62774378, 0.08959139, 0.12344046, 0.94897967,\n",
    "        0.98446017, 0.10304698, 0.69274853, 0.65948703, 0.96761688,\n",
    "        0.84741886, 0.71584026, 0.08163966, 0.12905297, 0.40769082,\n",
    "        0.12751238, 0.31982213, 0.12098797, 0.42515927, 0.14501096],\n",
    "       [0.50014376, 0.25764066, 0.89321616, 0.42712926, 0.0554846 ,\n",
    "        0.95114228, 0.71358808, 0.28102892, 0.16923638, 0.07674369,\n",
    "        0.81212113, 0.36325585, 0.86309813, 0.71734953, 0.94592495,\n",
    "        0.97832059, 0.99662547, 0.27319607, 0.45119052, 0.96076004],\n",
    "       [0.90253823, 0.24733245, 0.32683554, 0.52682568, 0.49748272,\n",
    "        0.12236442, 0.03298476, 0.20974979, 0.16296402, 0.58427078,\n",
    "        0.26675697, 0.46668716, 0.84086689, 0.64536565, 0.3106762 ,\n",
    "        0.11220032, 0.8994947 , 0.73787026, 0.6554433 , 0.6753808 ],\n",
    "       [0.18567906, 0.00399292, 0.47641247, 0.91865786, 0.41887556,\n",
    "        0.70834108, 0.17959301, 0.4380631 , 0.67724269, 0.69667343,\n",
    "        0.72800649, 0.17028013, 0.9146416 , 0.92159125, 0.41425331,\n",
    "        0.4006198 , 0.36910244, 0.63384678, 0.84616134, 0.17025744],\n",
    "       [0.92531473, 0.1655071 , 0.51796206, 0.21671123, 0.54801563,\n",
    "        0.27716926, 0.14992817, 0.05253494, 0.66211856, 0.68645151,\n",
    "        0.78970834, 0.35615426, 0.49116681, 0.94477949, 0.93507594,\n",
    "        0.47452467, 0.70245381, 0.43934428, 0.95295703, 0.4187147 ],\n",
    "       [0.33515453, 0.10705191, 0.25710262, 0.36302646, 0.82550822,\n",
    "        0.51990847, 0.72108586, 0.74177152, 0.11450249, 0.89406315,\n",
    "        0.34797566, 0.895625  , 0.46165193, 0.2135426 , 0.53488725,\n",
    "        0.72321418, 0.7878882 , 0.30746976, 0.76429345, 0.73536041]])\n",
    "y_seen = np.array([0.57218823, 0.20232463, 0.31767826, 0.62873191, 0.64141939,\n",
    "       0.49516018, 0.4578338 , 0.46423245, 0.55617846, 0.84011891,\n",
    "       0.78049052, 0.33286834, 0.4194628 , 0.39678775, 0.35077619,\n",
    "       0.47188588, 0.48166685, 0.37978283, 0.53653371, 0.22448738,\n",
    "       0.63234304, 0.45718868, 0.51364395, 0.63637147, 0.3139276 ,\n",
    "       0.64666755, 0.40074023, 0.63491258, 0.63916471, 0.48231435,\n",
    "       0.66133472, 0.50648569, 0.62976103, 0.57465927, 0.37493874,\n",
    "       0.27508023, 0.64724572, 0.37859445, 0.49631768, 0.37113892,\n",
    "       0.31092492, 0.32695493])\n",
    "x = np.array([0.09842664, 0.91452938, 0.42056915, 0.46360808, 0.65245194,\n",
    "       0.83982535, 0.78429744, 0.49834649, 0.28574984, 0.87174272,\n",
    "       0.61163489, 0.17329679, 0.46724292, 0.87860093, 0.52903206,\n",
    "       0.24919905, 0.98664782, 0.51081124, 0.82706065, 0.17630974])\n",
    "y = np.float64(0.3558477174746414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(10) * RBF(length_scale=100)\n",
    "cps = KernelRidgePredictionMachine(a=0.01, kernel=kernel)\n",
    "\n",
    "cps.learn_initial_training_set(X_seen, y_seen)\n",
    "\n",
    "cpd, precomputed = cps.predict_cpd(x=x, return_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
